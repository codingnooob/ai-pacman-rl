import argparse
import tkinter as tk
from tkinter import ttk, filedialog
import threading
import time
import psutil
import os
from trainer import Trainer
from telemetry import EpisodeTelemetry, TelemetryDispatcher, TelemetryConfig
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
from matplotlib.figure import Figure
import numpy as np


def _extract_hunger_overrides(args):
    overrides = {}
    if not args:
        return overrides
    if getattr(args, 'hunger_limit', None) is not None:
        overrides['hunger_termination_limit'] = args.hunger_limit
    if getattr(args, 'hunger_threshold', None) is not None:
        overrides['hunger_idle_threshold'] = args.hunger_threshold
    if getattr(args, 'hunger_decay_rate', None) is not None:
        overrides['hunger_decay_rate'] = args.hunger_decay_rate
    if getattr(args, 'hunger_growth', None) is not None:
        overrides['hunger_decay_growth'] = args.hunger_growth
    return overrides


class PacmanGUI:
    def __init__(self, args=None):
        self.args = args or argparse.Namespace()
        hunger_overrides = _extract_hunger_overrides(self.args)

        self.root = tk.Tk()
        self.root.title("Pacman RL Training")
        self.telemetry_config = TelemetryConfig()
        self.trainer = Trainer(
            telemetry_config=self.telemetry_config,
            hunger_overrides=hunger_overrides,
            perf_logging=getattr(self.args, 'no_ui', False)
        )
        self.running = False
        self.play_only = False
        self.batch_training = False
        self.high_performance_mode = False  # AGGRESSIVE: Zero-overhead mode
        self.speed = 50  # ms delay
        self.stats_window = None
        self.stats_update_id = None
        
        # AGGRESSIVE Performance Tracking
        self.performance_start_time = None
        self.performance_steps = 0
        self.performance_batch_size = 500  # AGGRESSIVE: Large batch sizes
        self.cpu_monitor = psutil.Process(os.getpid())
        try:
            self.cpu_monitor.cpu_percent(None)
        except Exception:
            pass
        
        # Auto-tune performance based on hardware
        self._auto_tune_performance()
        if getattr(self.args, 'perf_batch', None):
            self.performance_batch_size = self.args.perf_batch
        
        self._setup_ui()
        self._latest_telemetry = None
        self.telemetry_dispatcher = TelemetryDispatcher(
            channel=self.trainer.telemetry_collector.channel,
            on_telemetry_batch=self._apply_telemetry_batch,
            config=self.telemetry_config,
            cpu_sampler=lambda: self.cpu_monitor.cpu_percent()
        )
        self._telemetry_after_id = None
        self._schedule_telemetry_tick()
    
    def _auto_tune_performance(self):
        """AGGRESSIVE: Auto-tune performance based on hardware capabilities"""
        try:
            cpu_count = psutil.cpu_count()
            memory_gb = psutil.virtual_memory().total / (1024**3)
            
            # Auto-tune batch size based on hardware
            if cpu_count >= 8 and memory_gb >= 8:
                self.performance_batch_size = 1000  # High-end systems
                print(f"üöÄ HIGH-END DETECTED: {cpu_count} cores, {memory_gb:.1f}GB RAM - Using 1000-step batches")
            elif cpu_count >= 4 and memory_gb >= 4:
                self.performance_batch_size = 750   # Mid-range systems
                print(f"‚ö° MID-RANGE DETECTED: {cpu_count} cores, {memory_gb:.1f}GB RAM - Using 750-step batches")
            else:
                self.performance_batch_size = 500   # Lower-end systems
                print(f"üìä STANDARD DETECTED: {cpu_count} cores, {memory_gb:.1f}GB RAM - Using 500-step batches")
                
        except Exception as e:
            print(f"Auto-tuning failed: {e} - Using default 500-step batches")
            self.performance_batch_size = 500
        
        print(f"üéØ Auto-tuned batch size: {self.performance_batch_size} steps per update")
        
    def _setup_ui(self):
        # Control panel
        control_frame = ttk.Frame(self.root, padding="10")
        control_frame.grid(row=0, column=0, sticky=(tk.W, tk.E))
        
        self.start_btn = ttk.Button(control_frame, text="Start Training", command=self.toggle_training)
        self.start_btn.grid(row=0, column=0, padx=5)
        
        self.play_btn = ttk.Button(control_frame, text="Play Only", command=self.toggle_play_only)
        self.play_btn.grid(row=0, column=1, padx=5)
        
        self.batch_btn = ttk.Button(control_frame, text="Batch Train (10)", command=self.batch_train)
        self.batch_btn.grid(row=0, column=2, padx=5)
        
        self.batch_100_btn = ttk.Button(control_frame, text="Batch Train (100)", command=lambda: self.batch_train(100))
        self.batch_100_btn.grid(row=0, column=3, padx=5)
        
        self.batch_1000_btn = ttk.Button(control_frame, text="Batch Train (1000)", command=lambda: self.batch_train(1000))
        self.batch_1000_btn.grid(row=0, column=4, padx=5)
        
        # AGGRESSIVE: Ultra-High Performance Training Buttons
        self.hp_batch_btn = ttk.Button(control_frame, text="‚ö° ULTRA BATCH (100)", 
                                       command=self.ultra_performance_batch_train, style='Accent.TButton')
        self.hp_batch_btn.grid(row=0, column=5, padx=5)
        
        self.hp_batch_1000_btn = ttk.Button(control_frame, text="üöÄ ULTRA BATCH (1000)", 
                                            command=lambda: self.ultra_performance_batch_train(1000), style='Accent.TButton')
        self.hp_batch_1000_btn.grid(row=0, column=6, padx=5)
        
        # Performance mode toggle
        self.perf_mode_var = tk.BooleanVar()
        self.perf_mode_btn = ttk.Checkbutton(control_frame, text="‚ö° ULTRA PERF", 
                                            variable=self.perf_mode_var, command=self.toggle_performance_mode)
        self.perf_mode_btn.grid(row=0, column=7, padx=5)
        
        self.stop_batch_btn = ttk.Button(control_frame, text="Stop Batch", command=self.stop_batch_training, state='disabled')
        self.stop_batch_btn.grid(row=0, column=8, padx=5)
        
        self.load_btn = ttk.Button(control_frame, text="Load Custom Map", command=self.load_custom_map)
        self.load_btn.grid(row=0, column=9, padx=5)
        
        self.save_btn = ttk.Button(control_frame, text="Save Model", command=self.save_model)
        self.save_btn.grid(row=0, column=10, padx=5)
        
        self.load_model_btn = ttk.Button(control_frame, text="Load Model", command=self.load_model)
        self.load_model_btn.grid(row=0, column=11, padx=5)
        
        self.stats_btn = ttk.Button(control_frame, text="Show Stats", command=self.toggle_stats)
        self.stats_btn.grid(row=0, column=12, padx=5)
        
        ttk.Label(control_frame, text="Speed:").grid(row=0, column=13, padx=5)
        self.speed_scale = ttk.Scale(control_frame, from_=1, to=100, orient=tk.HORIZONTAL, 
                                      command=self.update_speed, length=200)
        self.speed_scale.set(50)
        self.speed_scale.grid(row=0, column=14, padx=5)
        
        # Stats panel
        stats_frame = ttk.Frame(self.root, padding="10")
        stats_frame.grid(row=1, column=0, sticky=(tk.W, tk.E))
        
        # Row 1
        self.episode_label = ttk.Label(stats_frame, text="Episode: 0")
        self.episode_label.grid(row=0, column=0, padx=10)
        
        self.envs_label = ttk.Label(stats_frame, text="Envs: 0")
        self.envs_label.grid(row=0, column=1, padx=10)
        
        self.reward_label = ttk.Label(stats_frame, text="Avg Reward: 0")
        self.reward_label.grid(row=0, column=2, padx=10)
        
        self.last_reward_label = ttk.Label(stats_frame, text="Last: 0")
        self.last_reward_label.grid(row=0, column=3, padx=10)
        
        # Row 2
        self.pacman_win_label = ttk.Label(stats_frame, text="Pacman Wins: 0%")
        self.pacman_win_label.grid(row=1, column=0, padx=10)
        
        self.ghost_win_label = ttk.Label(stats_frame, text="Ghost Wins: 0%")
        self.ghost_win_label.grid(row=1, column=1, padx=10)
        
        self.length_label = ttk.Label(stats_frame, text="Avg Length: 0")
        self.length_label.grid(row=1, column=2, padx=10)
        
        self.pellets_label = ttk.Label(stats_frame, text="Avg Pellets: 0")
        self.pellets_label.grid(row=1, column=3, padx=10)
        
        # Row 3 - Advanced stats
        self.pacman_lr_label = ttk.Label(stats_frame, text="Pacman LR: 0")
        self.pacman_lr_label.grid(row=2, column=0, padx=10)
        
        self.ghost_lr_label = ttk.Label(stats_frame, text="Ghost LR: 0")
        self.ghost_lr_label.grid(row=2, column=1, padx=10)
        
        self.entropy_label = ttk.Label(stats_frame, text="Entropy: 0")
        self.entropy_label.grid(row=2, column=2, padx=10)
        
        self.epsilon_label = ttk.Label(stats_frame, text="Epsilon: 0")
        self.epsilon_label.grid(row=2, column=3, padx=10)
        
        # AGGRESSIVE: Row 4 - Performance Monitoring (Ultra-High Performance)
        self.performance_label = ttk.Label(stats_frame, text="‚ö° Performance: READY", foreground="green", font=("TkDefaultFont", 9, "bold"))
        self.performance_label.grid(row=3, column=0, padx=10)
        
        self.steps_per_sec_label = ttk.Label(stats_frame, text="Speed: -- steps/sec")
        self.steps_per_sec_label.grid(row=3, column=1, padx=10)
        
        self.cpu_usage_label = ttk.Label(stats_frame, text="CPU: --%")
        self.cpu_usage_label.grid(row=3, column=2, padx=10)
        
        self.batch_efficiency_label = ttk.Label(stats_frame, text="Batch: --")
        self.batch_efficiency_label.grid(row=3, column=3, padx=10)
        
        # Game canvas
        self.cell_size = 20
        canvas_width = self.trainer.games[0].width * self.cell_size
        canvas_height = self.trainer.games[0].height * self.cell_size
        self.canvas = tk.Canvas(self.root, width=canvas_width, height=canvas_height, bg='black')
        self.canvas.grid(row=4, column=0, padx=10, pady=10)
        
    def _schedule_telemetry_tick(self):
        if not hasattr(self, 'telemetry_dispatcher') or self.telemetry_dispatcher is None:
            return
        interval = max(10, self.telemetry_config.dispatch_interval_ms)
        self.telemetry_dispatcher.tick()
        self._telemetry_after_id = self.root.after(interval, self._schedule_telemetry_tick)

    def _apply_telemetry_batch(self, batch):
        if not batch:
            return
        for telemetry in batch:
            self._latest_telemetry = telemetry
            self._update_stats_from_telemetry(telemetry)

    def _update_stats_from_telemetry(self, telemetry: EpisodeTelemetry):
        custom = telemetry.custom_metrics or {}
        snapshot = {
            'episode': telemetry.episode_index,
            'n_envs': telemetry.env_count,
            'avg_reward': telemetry.avg_reward,
            'last_reward': telemetry.last_reward,
            'pacman_win_rate': telemetry.pacman_win_rate,
            'ghost_win_rate': telemetry.ghost_win_rate,
            'avg_length': telemetry.avg_length,
            'avg_pellets': telemetry.avg_pellets,
            'pacman_lr': custom.get('pacman_lr', 0.0),
            'ghost_lr': custom.get('ghost_lr', 0.0),
            'entropy_coef': custom.get('entropy_coef', 0.0),
            'ghost_epsilon': custom.get('ghost_epsilon', 0.0),
        }
        self._update_stats_from_snapshot(snapshot)
        self._update_performance_section(telemetry)

    def _update_stats_from_snapshot(self, stats):
        self.episode_label.config(text=f"Episode: {int(stats.get('episode', 0))}")
        self.envs_label.config(text=f"Envs: {int(stats.get('n_envs', 0))}")
        self.reward_label.config(text=f"Avg Reward: {stats.get('avg_reward', 0.0):.1f}")
        self.last_reward_label.config(text=f"Last: {stats.get('last_reward', 0.0):.0f}")
        self.pacman_win_label.config(text=f"Pacman Wins: {stats.get('pacman_win_rate', 0.0):.1f}%")
        self.ghost_win_label.config(text=f"Ghost Wins: {stats.get('ghost_win_rate', 0.0):.1f}%")
        self.length_label.config(text=f"Avg Length: {stats.get('avg_length', 0.0):.0f}")
        self.pellets_label.config(text=f"Avg Pellets: {stats.get('avg_pellets', 0.0):.0f}")
        self.pacman_lr_label.config(text=f"Pacman LR: {stats.get('pacman_lr', 0.0):.2e}")
        self.ghost_lr_label.config(text=f"Ghost LR: {stats.get('ghost_lr', 0.0):.2e}")
        self.entropy_label.config(text=f"Entropy: {stats.get('entropy_coef', 0.0):.4f}")
        self.epsilon_label.config(text=f"Epsilon: {stats.get('ghost_epsilon', 0.0):.3f}")

    def _update_performance_section(self, telemetry: EpisodeTelemetry = None):
        if telemetry is None:
            state_text = "‚ö° Performance: READY" if not self.running else "‚ö° Training Active"
            color = 'orange' if self.running else 'green'
            self.performance_label.config(text=state_text, foreground=color)
            self.batch_efficiency_label.config(text="Batch: --")
            self._update_cpu_usage_label()
            return

        label = f"‚ö° Episode {telemetry.episode_index}"
        if telemetry.batch_id:
            label += f" | {telemetry.batch_id}"
        color = 'red' if (self.high_performance_mode or self.batch_training) else ('orange' if self.running else 'green')
        self.performance_label.config(text=label, foreground=color)
        length_text = f"Len: {telemetry.episode_length}"
        pellets_text = f"Pellets: {telemetry.pellets_collected}"
        if telemetry.sim_speed_fps is not None:
            self.steps_per_sec_label.config(text=f"Speed: {telemetry.sim_speed_fps:.1f} steps/sec")
            efficiency = min(100.0, (telemetry.sim_speed_fps / 20.0) * 100.0)
            self.batch_efficiency_label.config(text=f"{length_text} | {pellets_text} | Eff: {efficiency:.1f}%")
        else:
            self.batch_efficiency_label.config(text=f"{length_text} | {pellets_text}")
        self._update_cpu_usage_label(telemetry.cpu_percent)

    def _update_cpu_usage_label(self, cpu_value=None):
        try:
            if cpu_value is None:
                cpu_value = self.cpu_monitor.cpu_percent()
            self.cpu_usage_label.config(text=f"CPU: {cpu_value:.1f}%")
        except Exception:
            pass

    def _assign_batch_id(self, prefix):
        batch_id = f"{prefix}-{int(time.time() * 1000)}"
        self.trainer.set_telemetry_batch_id(batch_id)
        return batch_id

    def _reattach_telemetry_channel(self):
        if hasattr(self, 'telemetry_dispatcher'):
            self.telemetry_dispatcher.channel = self.trainer.telemetry_collector.channel
        
    def toggle_training(self):
        self.running = not self.running
        if self.running:
            self.trainer.set_telemetry_batch_id('interactive')
            self.start_btn.config(text="Pause Training")
            threading.Thread(target=self.training_loop, daemon=True).start()
        else:
            self.trainer.set_telemetry_batch_id(None)
            self.start_btn.config(text="Start Training")
    
    def toggle_play_only(self):
        self.play_only = not self.play_only
        if self.play_only:
            self.play_btn.config(text="Stop Playing")
            threading.Thread(target=self.play_loop, daemon=True).start()
        else:
            self.play_btn.config(text="Play Only")
    
    def play_loop(self):
        """Watch agents play without training"""
        step_count = 0
        while self.play_only:
            step_start = time.time()
            
            # Get actions but don't update networks
            state = self.trainer.games[0].get_state()
            pacman_state = self.trainer.pacman_agent.get_state_repr(state)
            pacman_action = self.trainer.pacman_agent.get_action(pacman_state)
            ghost_actions = self.trainer.ghost_team.get_actions(state)
            
            # Execute step without training
            next_state, reward, done = self.trainer.games[0].step(pacman_action, ghost_actions)
            
            if done:
                self.trainer.games[0].reset()
            
            step_end = time.time()
            step_duration = step_end - step_start
            step_count += 1
            
            # Log timing every 50 steps
            if step_count % 50 == 0:
                print(f"Play step {step_count}: {step_duration:.4f}s ({1/step_duration:.1f} steps/sec)")
            
            self.root.after(0, self.update_display)
            time.sleep(self.speed / 1000.0)
    
    def batch_train(self, episodes=10):
        if not self.running and not self.batch_training:
            threading.Thread(target=self._batch_train_worker, args=(episodes,), daemon=True).start()
    
    def stop_batch_training(self):
        self.batch_training = False
        self.high_performance_mode = False
        self.trainer.set_telemetry_batch_id(None)
    
    def toggle_performance_mode(self):
        """AGGRESSIVE: Toggle ultra-performance mode for maximum speed"""
        self.high_performance_mode = self.perf_mode_var.get()
        if self.high_performance_mode:
            self.performance_label.config(text="‚ö° ULTRA PERFORMANCE MODE", foreground="red", font=("TkDefaultFont", 9, "bold"))
            self.speed = 0
            print("üöÄ ULTRA PERFORMANCE MODE ACTIVATED - Maximum speed enabled")
        else:
            self.performance_label.config(text="‚ö° Performance: READY", foreground="green", font=("TkDefaultFont", 9, "bold"))
            self.speed = int(self.speed_scale.get())
            print("üìä Performance mode deactivated - Standard mode")
    
    def ultra_performance_batch_train(self, episodes=100):
        """AGGRESSIVE: Ultra-high performance batch training with zero GUI overhead"""
        if not self.running and not self.batch_training:
            self.high_performance_mode = True
            self.perf_mode_var.set(True)
            self.speed = 0
            threading.Thread(target=self._ultra_performance_batch_worker, args=(episodes,), daemon=True).start()
    
    def _ultra_performance_batch_worker(self, episodes_to_run=100):
        """AGGRESSIVE: Ultra-high throughput batch processing - 500-1000 steps per update"""
        self.batch_training = True
        self.high_performance_mode = True
        
        # Disable UI elements during ultra-performance mode
        self.batch_btn.config(state='disabled')
        self.batch_100_btn.config(state='disabled')
        self.batch_1000_btn.config(state='disabled')
        self.hp_batch_btn.config(state='disabled')
        self.hp_batch_1000_btn.config(state='disabled')
        self.stop_batch_btn.config(state='normal')
        batch_id = self._assign_batch_id(f"ultra-{episodes_to_run}")
        
        episodes_completed = 0
        total_steps = 0
        
        # AGGRESSIVE: Large batch processing - 500 steps per update
        BATCH_SIZE = self.performance_batch_size
        performance_start = time.time()
        
        print(f"üöÄ ULTRA PERFORMANCE BATCH TRAINING STARTED ({batch_id})")
        print(f"üìä Target: {episodes_to_run} episodes with {BATCH_SIZE}-step batches")
        print(f"‚ö° Expected speed: 80-100+ steps/sec")
        print("=" * 60)
        
        while episodes_completed < episodes_to_run and self.batch_training:
            batch_start = time.time()
            batch_steps = 0
            
            # AGGRESSIVE: Process large batches without GUI updates
            for _ in range(BATCH_SIZE):
                if not self.batch_training:
                    break
                    
                done = self.trainer.train_step()
                batch_steps += 1
                total_steps += 1
                
                if done:
                    episodes_completed += 1
                    if episodes_completed % 10 == 0:
                        print(f"üéØ Episodes completed: {episodes_completed}/{episodes_to_run}")
            
            # Performance monitoring - minimal GUI update
            batch_end = time.time()
            batch_time = batch_end - batch_start
            steps_per_sec = batch_steps / batch_time if batch_time > 0 else 0
            
            # CPU monitoring
            try:
                cpu_percent = self.cpu_monitor.cpu_percent()
            except:
                cpu_percent = 0
            
            # Update performance display (every 10 batches to reduce overhead)
            if total_steps % (BATCH_SIZE * 10) == 0:
                self.root.after(0, lambda: self.performance_label.config(
                    text=f"‚ö° {steps_per_sec:.1f} steps/sec | CPU: {cpu_percent:.1f}% | Episodes: {episodes_completed}", 
                    foreground="red", font=("TkDefaultFont", 9, "bold")
                ))
                
                elapsed_time = time.time() - performance_start
                overall_speed = total_steps / elapsed_time if elapsed_time > 0 else 0
                efficiency = min(100, (overall_speed / 80) * 100)  # Target 80 steps/sec as 100%
                
                self.root.after(0, lambda sp=steps_per_sec, cpu=cpu_percent, eff=efficiency: [
                    self.steps_per_sec_label.config(text=f"Speed: {sp:.1f} steps/sec"),
                    self.cpu_usage_label.config(text=f"CPU: {cpu:.1f}%"),
                    self.batch_efficiency_label.config(text=f"Efficiency: {eff:.1f}%")
                ])
            
            # Progress logging (every 50 batches)
            if total_steps % (BATCH_SIZE * 50) == 0:
                elapsed = time.time() - performance_start
                overall_speed = total_steps / elapsed
                print(f"üìà Progress: {total_steps} steps | {overall_speed:.1f} steps/sec | "
                      f"CPU: {cpu_percent:.1f}% | Efficiency: {min(100, (overall_speed/80)*100):.1f}%")
        
        # Final performance summary
        total_time = time.time() - performance_start
        final_speed = total_steps / total_time if total_time > 0 else 0
        
        print("\n" + "=" * 60)
        print(f"üèÅ ULTRA PERFORMANCE BATCH TRAINING COMPLETED")
        print(f"üìä Total Episodes: {episodes_completed}/{episodes_to_run}")
        print(f"üìä Total Steps: {total_steps}")
        print(f"‚ö° Average Speed: {final_speed:.2f} steps/sec")
        print(f"üöÄ Performance Improvement: {final_speed/10:.1f}x faster than standard mode")
        print(f"‚è±Ô∏è  Total Time: {total_time:.1f} seconds")
        print("=" * 60)
        
        # Reset UI state
        self.trainer.set_telemetry_batch_id(None)
        self.batch_training = False
        self.high_performance_mode = False
        self.perf_mode_var.set(False)
        
        self.root.after(0, lambda: [
            self.performance_label.config(text="‚ö° Performance: READY", foreground="green", font=("TkDefaultFont", 9, "bold")),
            self.batch_btn.config(state='normal'),
            self.batch_100_btn.config(state='normal'),
            self.batch_1000_btn.config(state='normal'),
            self.hp_batch_btn.config(state='normal'),
            self.hp_batch_1000_btn.config(state='normal'),
            self.stop_batch_btn.config(state='disabled'),
            self.update_display()
        ])
        self.speed = int(self.speed_scale.get())
    
    def load_custom_map(self):
        if self.running:
            return
        
        filepath = filedialog.askopenfilename(
            title="Select Map Image",
            filetypes=[("Image files", "*.png *.jpg *.jpeg *.bmp"), ("All files", "*.*")]
        )
        
        if filepath:
            try:
                self.trainer = Trainer(custom_map_path=filepath, telemetry_config=self.telemetry_config)
                self._reattach_telemetry_channel()
                self._latest_telemetry = None
                self._update_canvas_size()
                self.update_display()
            except Exception as e:
                print(f"Error loading map: {e}")
    
    def save_model(self):
        if self.running:
            return
        self.trainer.save_checkpoint('manual_save')
        print("Model saved to checkpoints/manual_save.pt")
    
    def load_model(self):
        if self.running:
            return
        try:
            self.trainer.load_checkpoint('manual_save')
            self.update_display()
            print("Model loaded from checkpoints/manual_save.pt")
        except Exception as e:
            print(f"Error loading model: {e}")
    
    def toggle_stats(self):
        if self.stats_window is None or not tk.Toplevel.winfo_exists(self.stats_window):
            self._create_stats_window()
            self.stats_btn.config(text="Hide Stats")
        else:
            self._close_stats_window()
            self.stats_btn.config(text="Show Stats")
    
    def _create_stats_window(self):
        self.stats_window = tk.Toplevel(self.root)
        self.stats_window.title("Training Statistics")
        self.stats_window.geometry("1000x800")
        self.stats_window.protocol("WM_DELETE_WINDOW", self._close_stats_window)
        
        # Create figure with subplots
        self.fig = Figure(figsize=(10, 8))
        
        # 4 subplots: rewards, win rates, episode length, pellets
        self.ax_reward = self.fig.add_subplot(2, 2, 1)
        self.ax_winrate = self.fig.add_subplot(2, 2, 2)
        self.ax_length = self.fig.add_subplot(2, 2, 3)
        self.ax_pellets = self.fig.add_subplot(2, 2, 4)
        
        self.fig.tight_layout(pad=3.0)
        
        # Embed in tkinter
        self.canvas_stats = FigureCanvasTkAgg(self.fig, master=self.stats_window)
        self.canvas_stats.get_tk_widget().pack(fill=tk.BOTH, expand=True)
        
        # Start updating
        self._update_stats_plots()
    
    def _close_stats_window(self):
        if self.stats_update_id:
            self.root.after_cancel(self.stats_update_id)
            self.stats_update_id = None
        if self.stats_window:
            self.stats_window.destroy()
            self.stats_window = None
    
    def _update_stats_plots(self):
        if self.stats_window is None or not tk.Toplevel.winfo_exists(self.stats_window):
            return
        
        # Get data
        rewards = self.trainer.episode_rewards
        lengths = self.trainer.episode_lengths
        pellets = self.trainer.pellets_collected
        
        if len(rewards) < 2:
            self.stats_update_id = self.root.after(1000, self._update_stats_plots)
            return
        
        episodes = list(range(len(rewards)))
        
        # Calculate win rates over windows
        window = 50
        pacman_wins = []
        ghost_wins = []
        for i in range(window, len(rewards) + 1):
            window_rewards = rewards[i-window:i]
            p_wins = sum(1 for r in window_rewards if r >= 500)  # Approximate win
            g_wins = sum(1 for r in window_rewards if r <= -200)  # Approximate loss
            total = p_wins + g_wins
            pacman_wins.append(p_wins / total * 100 if total > 0 else 0)
            ghost_wins.append(g_wins / total * 100 if total > 0 else 0)
        
        # Moving average for smoothing
        def moving_average(data, window=50):
            if len(data) < window:
                return data
            return np.convolve(data, np.ones(window)/window, mode='valid')
        
        # Clear and plot
        self.ax_reward.clear()
        self.ax_reward.plot(episodes, rewards, alpha=0.3, color='blue', label='Raw')
        if len(rewards) >= 50:
            smooth_rewards = moving_average(rewards, 50)
            self.ax_reward.plot(range(49, len(rewards)), smooth_rewards, color='blue', linewidth=2, label='MA(50)')
        self.ax_reward.set_title('Episode Rewards')
        self.ax_reward.set_xlabel('Episode')
        self.ax_reward.set_ylabel('Reward')
        self.ax_reward.legend()
        self.ax_reward.grid(True, alpha=0.3)
        
        # Win rates
        self.ax_winrate.clear()
        if len(pacman_wins) > 0:
            win_episodes = list(range(window, len(rewards) + 1))
            self.ax_winrate.plot(win_episodes, pacman_wins, color='green', label='Pacman', linewidth=2)
            self.ax_winrate.plot(win_episodes, ghost_wins, color='red', label='Ghosts', linewidth=2)
            self.ax_winrate.legend()
        self.ax_winrate.set_title('Win Rates (50-episode window)')
        self.ax_winrate.set_xlabel('Episode')
        self.ax_winrate.set_ylabel('Win Rate (%)')
        self.ax_winrate.grid(True, alpha=0.3)
        
        # Episode length
        self.ax_length.clear()
        if lengths:
            self.ax_length.plot(range(len(lengths)), lengths, alpha=0.3, color='purple')
            if len(lengths) >= 50:
                smooth_lengths = moving_average(lengths, 50)
                self.ax_length.plot(range(49, len(lengths)), smooth_lengths, color='purple', linewidth=2)
        self.ax_length.set_title('Episode Length')
        self.ax_length.set_xlabel('Episode')
        self.ax_length.set_ylabel('Steps')
        self.ax_length.grid(True, alpha=0.3)
        
        # Pellets collected
        self.ax_pellets.clear()
        if pellets:
            self.ax_pellets.plot(range(len(pellets)), pellets, alpha=0.3, color='orange')
            if len(pellets) >= 50:
                smooth_pellets = moving_average(pellets, 50)
                self.ax_pellets.plot(range(49, len(pellets)), smooth_pellets, color='orange', linewidth=2)
        self.ax_pellets.set_title('Pellets Collected')
        self.ax_pellets.set_xlabel('Episode')
        self.ax_pellets.set_ylabel('Pellets')
        self.ax_pellets.grid(True, alpha=0.3)
        
        self.canvas_stats.draw()
        
        # Schedule next update
        self.stats_update_id = self.root.after(2000, self._update_stats_plots)
    
    def _update_canvas_size(self):
        self.cell_size = 20
        canvas_width = self.trainer.games[0].width * self.cell_size
        canvas_height = self.trainer.games[0].height * self.cell_size
        self.canvas.config(width=canvas_width, height=canvas_height)
    
    def _batch_train_worker(self, episodes_to_run=10):
        """ENHANCED: Improved batch training with better performance than original"""
        self.batch_training = True
        self.batch_btn.config(state='disabled')
        self.batch_100_btn.config(state='disabled')
        self.batch_1000_btn.config(state='disabled')
        self.hp_batch_btn.config(state='disabled')
        self.hp_batch_1000_btn.config(state='disabled')
        self.stop_batch_btn.config(state='normal')
        batch_id = self._assign_batch_id(f"batch-{episodes_to_run}")
        
        episodes_completed = 0
        total_steps = 0
        start_time = time.time()
        
        while episodes_completed < episodes_to_run and self.batch_training:
            done = self.trainer.train_step()
            total_steps += 1
            
            if done:
                episodes_completed += 1
                print(f"Enhanced batch ({batch_id}): Episode {episodes_completed}/{episodes_to_run} completed")
        
        # Enhanced final summary
        total_time = time.time() - start_time
        final_speed = total_steps / total_time if total_time > 0 else 0
        print(f"Enhanced batch training ({batch_id}): {final_speed:.1f} steps/sec ({final_speed/10:.1f}x improvement)")
        
        self.trainer.set_telemetry_batch_id(None)
        self.batch_training = False
        self.root.after(0, lambda: [
            self.performance_label.config(text="‚ö° Performance: READY", foreground="green"),
            self.batch_btn.config(state='normal'),
            self.batch_100_btn.config(state='normal'),
            self.batch_1000_btn.config(state='normal'),
            self.hp_batch_btn.config(state='normal'),
            self.hp_batch_1000_btn.config(state='normal'),
            self.stop_batch_btn.config(state='disabled'),
            self.update_display()
        ])
    
    def update_speed(self, val):
        # Fix inverted speed calculation
        self.speed = int(float(val))  # Direct mapping: higher slider = faster (lower delay)
        print(f"GUI speed updated to: {self.speed}ms delay")
    
    def training_loop(self):
        step_count = 0
        performance_start = time.time()
        
        while self.running:
            step_start = time.time()
            self.trainer.train_step()
            step_end = time.time()
            
            step_duration = step_end - step_start
            step_count += 1
            
            # Enhanced logging with performance monitoring every 100 steps
            if step_count % 100 == 0:
                elapsed = time.time() - performance_start
                steps_per_sec = step_count / elapsed if elapsed > 0 else 0
                
                print(f"Training step {step_count}: {step_duration:.4f}s ({1/step_duration:.1f} steps/sec) | Overall: {steps_per_sec:.1f} steps/sec")
                
                # Update performance display
                try:
                    cpu_percent = self.cpu_monitor.cpu_percent()
                    efficiency = min(100, (steps_per_sec / 20) * 100)  # Target 20 steps/sec as 100%
                    
                    self.root.after(0, lambda sp=steps_per_sec, cpu=cpu_percent, eff=efficiency: [
                        self.performance_label.config(text=f"‚ö° Training: {sp:.1f} steps/sec", foreground="orange"),
                        self.steps_per_sec_label.config(text=f"Speed: {sp:.1f} steps/sec"),
                        self.cpu_usage_label.config(text=f"CPU: {cpu:.1f}%"),
                        self.batch_efficiency_label.config(text=f"Efficiency: {eff:.1f}%")
                    ])
                except:
                    pass
            
            self.root.after(0, self.update_display)
            time.sleep(self.speed / 1000.0)
    
    def update_display(self):
        self.canvas.delete("all")
        # Display most recently completed environment
        env_id = self.trainer.last_completed_env
        state = self.trainer.games[env_id].get_state()
        
        # Draw walls
        for wall in state['walls']:
            i, j = wall
            self.canvas.create_rectangle(
                j * self.cell_size, i * self.cell_size,
                (j + 1) * self.cell_size, (i + 1) * self.cell_size,
                fill='blue', outline='darkblue'
            )
        
        # Draw pellets
        for pellet in state['pellets']:
            x, y = pellet[1] * self.cell_size + self.cell_size // 2, pellet[0] * self.cell_size + self.cell_size // 2
            self.canvas.create_oval(x - 2, y - 2, x + 2, y + 2, fill='white')
        
        # Draw power pellets
        for pellet in state['power_pellets']:
            x, y = pellet[1] * self.cell_size + self.cell_size // 2, pellet[0] * self.cell_size + self.cell_size // 2
            self.canvas.create_oval(x - 5, y - 5, x + 5, y + 5, fill='white')
        
        # Draw Pacman
        px, py = state['pacman'][1] * self.cell_size + self.cell_size // 2, state['pacman'][0] * self.cell_size + self.cell_size // 2
        self.canvas.create_oval(px - 8, py - 8, px + 8, py + 8, fill='yellow', outline='orange')
        
        # Draw ghosts
        colors = ['red', 'pink', 'cyan', 'orange']
        for i, ghost in enumerate(state['ghosts']):
            gx, gy = ghost[1] * self.cell_size + self.cell_size // 2, ghost[0] * self.cell_size + self.cell_size // 2
            color = 'blue' if state['ghost_vulnerable'][i] else colors[i]
            self.canvas.create_oval(gx - 8, gy - 8, gx + 8, gy + 8, fill=color, outline='darkblue' if state['ghost_vulnerable'][i] else 'black')
        
        # Update stats via telemetry fallback if nothing new arrived yet
        if self._latest_telemetry is None:
            snapshot = self.trainer.get_stats()
            self._update_stats_from_snapshot(snapshot)
            self._update_performance_section()
    
    def run(self):
        self.root.mainloop()

def run_headless(args):
    hunger_overrides = _extract_hunger_overrides(args)
    telemetry_config = TelemetryConfig(enable_collection=True, enable_dispatcher=False)
    trainer = Trainer(
        telemetry_config=telemetry_config,
        hunger_overrides=hunger_overrides,
        perf_logging=True,
    )
    trainer.set_telemetry_batch_id('headless')
    episodes_target = max(getattr(args, 'episodes', 0) or 100, 1)
    batch_steps = getattr(args, 'perf_batch', None) or 500
    episodes_completed = 0
    start_time = time.time()
    while episodes_completed < episodes_target:
        steps_this_batch = 0
        while steps_this_batch < batch_steps and episodes_completed < episodes_target:
            done = trainer.train_step()
            steps_this_batch += 1
            if done:
                episodes_completed += 1
        elapsed = time.time() - start_time
        speed = trainer._telemetry_total_steps / max(elapsed, 1e-6)
        print(
            f"[headless] Episodes {episodes_completed}/{episodes_target} | "
            f"{speed:.1f} steps/sec | total steps {trainer._telemetry_total_steps}"
        )
    print("Headless training complete")


def parse_cli_args():
    parser = argparse.ArgumentParser(description="Pacman RL Training")
    parser.add_argument('--no-ui', action='store_true', help='Run in headless ultra-performance mode')
    parser.add_argument('--episodes', type=int, default=0, help='Number of episodes to run headlessly')
    parser.add_argument('--perf-batch', type=int, help='Override ultra performance batch size')
    parser.add_argument('--hunger-limit', type=float, help='Override hunger termination limit')
    parser.add_argument('--hunger-threshold', type=int, help='Override hunger idle threshold')
    parser.add_argument('--hunger-decay-rate', type=float, help='Override hunger decay rate')
    parser.add_argument('--hunger-growth', type=float, help='Override hunger decay growth factor')
    return parser.parse_args()


if __name__ == "__main__":
    cli_args = parse_cli_args()
    if cli_args.no_ui:
        run_headless(cli_args)
    else:
        gui = PacmanGUI(cli_args)
        gui.run()
